{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "                  MMM        ABT  ABBV  ABMD        ACN       ATVI       ADBE  \\\n",
      "Date                                                                            \n",
      "2009-12-31  62.630104  20.125896   NaN  8.73  33.262230   9.956354  36.779999   \n",
      "2010-01-04  62.895260  20.301096   NaN  8.74  33.719078  10.126624  37.090000   \n",
      "2010-01-05  62.501301  20.137075   NaN  8.53  33.927479  10.144546  37.700001   \n",
      "2010-01-06  63.387695  20.248909   NaN  8.40  34.288147  10.090778  37.619999   \n",
      "2010-01-07  63.433144  20.416655   NaN  8.40  34.256084   9.848815  36.889999   \n",
      "\n",
      "             AMD        AAP        AES ...        WYNN        XEL        XRX  \\\n",
      "Date                                   ...                                     \n",
      "2009-12-31  9.68  39.320717  10.388851 ...   38.204304  14.407495  16.884586   \n",
      "2010-01-04  9.70  39.223591  10.669841 ...   41.963718  14.312444  17.223871   \n",
      "2010-01-05  9.71  38.990475  10.560567 ...   44.515926  14.142703  17.243830   \n",
      "2010-01-06  9.57  39.330433  10.451293 ...   43.932011  14.169861  17.084164   \n",
      "2010-01-07  9.47  39.320717  10.459099 ...   44.870213  14.108753  17.163994   \n",
      "\n",
      "                 XLNX  XYL        YUM       ZBRA        ZBH       ZION  ZTS  \n",
      "Date                                                                         \n",
      "2009-12-31  19.707844  NaN  19.312820  28.350000  54.959087  11.494728  NaN  \n",
      "2010-01-04  19.959499  NaN  19.379101  28.670000  55.805180  11.942696  NaN  \n",
      "2010-01-05  19.707844  NaN  19.312820  28.620001  57.571747  12.363780  NaN  \n",
      "2010-01-06  19.574154  NaN  19.174761  28.400000  57.553162  13.438891  NaN  \n",
      "2010-01-07  19.377548  NaN  19.169235  27.690001  58.873451  14.944045  NaN  \n",
      "\n",
      "[5 rows x 505 columns]\n"
     ]
    }
   ],
   "source": [
    "import bs4 as bs\n",
    "import datetime as dt\n",
    "import os\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import pickle\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def save_sp500_tickers():\n",
    "    resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "    tickers = []\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[0].text\n",
    "        tickers.append(ticker)\n",
    "    with open(\"sp500tickers.pickle\", \"wb\") as f:\n",
    "        pickle.dump(tickers, f)\n",
    "    return tickers\n",
    "\n",
    "\n",
    "# save_sp500_tickers()\n",
    "def get_data_from_yahoo(reload_sp500=False):\n",
    "    if reload_sp500:\n",
    "        tickers = save_sp500_tickers()\n",
    "    else:\n",
    "        with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "            tickers = pickle.load(f)\n",
    "    if not os.path.exists('stock_dfs'):\n",
    "        os.makedirs('stock_dfs')\n",
    "\n",
    "    start = dt.datetime(2010, 1, 1)\n",
    "    end = dt.datetime.now()\n",
    "    for ticker in tickers:\n",
    "        ticker = ticker.strip(\"\\n\")\n",
    "        if \".\" in ticker:\n",
    "            ticker = ticker.replace(\".\",\"-\")\n",
    "        #print(ticker)\n",
    "        # just in case your connection breaks, we'd like to save our progress!\n",
    "        if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):\n",
    "            df = web.DataReader(ticker, 'yahoo', start, end)\n",
    "            #iex-tops econdb\n",
    "            df.reset_index(inplace=True)\n",
    "            df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "            #df = df.drop(\"Symbol\", axis=1)\n",
    "            df.to_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "        else:\n",
    "            print('Already have {}'.format(ticker))\n",
    "\n",
    "\n",
    "#get_data_from_yahoo()\n",
    "def compile_data():\n",
    "    with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "        tickers = pickle.load(f)\n",
    "\n",
    "    main_df = pd.DataFrame()\n",
    "\n",
    "    for count, ticker in enumerate(tickers):\n",
    "        ticker = ticker.strip(\"\\n\")\n",
    "        if \".\" in ticker:\n",
    "            ticker = ticker.replace(\".\",\"-\")\n",
    "        df = pd.read_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "        df.set_index('Date', inplace=True)\n",
    "        df.rename(columns={'Adj Close': ticker}, inplace=True)\n",
    "        df.drop(['Open', 'High', 'Low', 'Close', 'Volume'], 1, inplace=True)\n",
    "\n",
    "        \n",
    "        if main_df.empty:\n",
    "            main_df = df\n",
    "        else:\n",
    "            main_df = main_df.join(df, how='outer')\n",
    "\n",
    "        if count % 10 == 0:\n",
    "            print(count)\n",
    "    print(main_df.head())\n",
    "    main_df.to_csv('sp500_joined_closes.csv')\n",
    "compile_data()\n",
    "def visualize_data():\n",
    "    df = pd.read_csv('sp500_joined_closes.csv')\n",
    "    df_corr = df.corr()\n",
    "    print(df_corr.head())\n",
    "    df_corr.to_csv('sp500corr.csv')\n",
    "    data1 = df_corr.values\n",
    "    fig1 = plt.figure()\n",
    "    ax1 = fig1.add_subplot(111)\n",
    "\n",
    "    heatmap1 = ax1.pcolor(data1, cmap=plt.cm.RdYlGn)\n",
    "    fig1.colorbar(heatmap1)\n",
    "\n",
    "    ax1.set_xticks(np.arange(data1.shape[1]) + 0.5, minor=False)\n",
    "    ax1.set_yticks(np.arange(data1.shape[0]) + 0.5, minor=False)\n",
    "    ax1.invert_yaxis()\n",
    "    ax1.xaxis.tick_top()\n",
    "    column_labels = df_corr.columns\n",
    "    row_labels = df_corr.index\n",
    "    ax1.set_xticklabels(column_labels,fontsize=1)\n",
    "    ax1.set_yticklabels(row_labels,fontsize=1)\n",
    "    ax1.xaxis.set_tick_params(labelsize=1)\n",
    "    ax1.yaxis.set_tick_params(labelsize=1)\n",
    "    plt.xticks(rotation=90)\n",
    "    heatmap1.set_clim(-1, 1)\n",
    "    #plt.tight_layout()\n",
    "    #plt.show()\n",
    "    plt.savefig('correlation.png',dpi=1000)\n",
    "#visualize_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
